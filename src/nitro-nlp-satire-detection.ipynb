{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7980800,"sourceType":"datasetVersion","datasetId":4697210},{"sourceId":7986515,"sourceType":"datasetVersion","datasetId":4701217},{"sourceId":7986642,"sourceType":"datasetVersion","datasetId":4701298},{"sourceId":7987437,"sourceType":"datasetVersion","datasetId":4701847}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T07:07:34.570207Z","iopub.execute_input":"2024-03-31T07:07:34.570472Z","iopub.status.idle":"2024-03-31T07:07:52.615358Z","shell.execute_reply.started":"2024-03-31T07:07:34.570446Z","shell.execute_reply":"2024-03-31T07:07:52.614525Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-31 07:07:44.562640: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-31 07:07:44.562737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-31 07:07:44.695900: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U transformers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shutil import copyfile\n\ncopyfile(src = \"/kaggle/input/nitro-nlp-satire/random_seed_setter.py\", dst = \"/kaggle/working/seed_setter.py\")\n\nfrom seed_setter import *","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:07:54.541523Z","iopub.execute_input":"2024-03-31T07:07:54.542155Z","iopub.status.idle":"2024-03-31T07:07:54.552594Z","shell.execute_reply.started":"2024-03-31T07:07:54.542121Z","shell.execute_reply":"2024-03-31T07:07:54.551771Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"set_random_seeds()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:07:57.043607Z","iopub.execute_input":"2024-03-31T07:07:57.044177Z","iopub.status.idle":"2024-03-31T07:07:57.085402Z","shell.execute_reply.started":"2024-03-31T07:07:57.044145Z","shell.execute_reply":"2024-03-31T07:07:57.084452Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"NumPy random seed set with value: 42\nTensorFlow random seed set with value: 42\nPyTorch random seed set with value: 42\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nitro-nlp-satire/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nitro-nlp-satire/test.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLEANER = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\nPUNCT_REMOVE = re.compile('[^\\w\\s]|_')\ndef clean_text(text):\n   if isinstance(text, str):\n        text = CLEANER.sub('', text)\n        text = PUNCT_REMOVE.sub('', text)\n        text = text.lower()\n        # Remove leading and trailing whitespaces\n        text = text.strip()\n        # Remove extra spaces\n        text = re.sub(' +', ' ', text)\n        # correct the ș/ț diacritics before feeding it to the model \n        text = text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n        return text\n   else:  \n        return \"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clean text\ntrain_df['title'] = train_df['title'].apply(clean_text)\ntrain_df['content'] = train_df['content'].apply(clean_text)\ntest_df['title'] = test_df['title'].apply(clean_text)\ntest_df['content'] = test_df['content'].apply(clean_text)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenate title & content columns\ntrain_df['input'] = train_df['title'].astype(str) + '  ' + train_df['content'].astype(str)\ntest_df['input'] = test_df['title'].astype(str) + '  ' + test_df['content'].astype(str)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get features & labels\nX = train_df['input']  \ny = train_df['class']\nX_final_test = test_df['input']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create train, validation & test split \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size =0.2, stratify=y)\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, stratify=y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\nmodel = AutoModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to generate the embeddings for the sentences\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ndef get_embeddings(sentences):\n    batch_size = 64  \n    # list to store embeddings\n    all_embeddings = []\n    for i in range(0, len(sentences), batch_size):\n        # tokenize the batch of sentences\n        inputs = tokenizer(sentences[i:i+batch_size], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n        # move inputs to gpu\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n        with torch.no_grad():\n            outputs = model(**inputs)\n        # get embeddings from the last hidden state\n        embeddings = outputs.last_hidden_state.mean(dim=1).detach().cpu()\n        all_embeddings.append(embeddings)\n\n    all_embeddings_tensor = torch.cat(all_embeddings, dim=0)\n    return all_embeddings_tensor\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get embeddings for train & save them\nsentences_train = X_train.tolist()\nembeddings_train = get_embeddings(sentences_train)\nembeddings_train = embeddings_train.numpy()\ny_train_numeric = np.array(y_train, dtype=int)\nnp.save(\"embeddings_train.npy\", embeddings_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train random forest classifier\ntrain_random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\ntrain_random_forest.fit(embeddings_train, y_train_numeric)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get embeddings for validation & test set & save them\nsentences_test = X_test.tolist()\ny_test_numeric = np.array(y_test, dtype=int)\nembeddings_test = get_embeddings(sentences_test)\n\nsentences_val = X_val.tolist()\ny_val_numeric = np.array(y_val, dtype=int)\nembeddings_val = get_embeddings(sentences_val)\n\nembeddings_test = embeddings_test.numpy()\nnp.save(\"embeddings_test.npy\", embeddings_test)\nembeddings_val = embeddings_val.numpy()\nnp.save(\"embeddings_val.npy\", embeddings_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenate validation & test \ny_concat_test = np.concatenate((y_val_numeric,y_test_numeric))\nembeddings_concat_test = np.concatenate((embeddings_val,embeddings_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save labels\nnp.save(\"y_test_numeric.npy\", y_test_numeric)\nnp.save(\"y_train_numeric.npy\", y_train_numeric)\nnp.save(\"y_val_numeric.npy\", y_val_numeric)\nnp.save(\"y_concat_test.npy\", y_concat_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make predictions on the validation&test concatenated\ny_pred = train_random_forest.predict(embeddings_concat_test)\naccuracy = accuracy_score(y_concat_test, y_pred)\nprecision = precision_score(y_concat_test, y_pred)\nrecall = recall_score(y_concat_test, y_pred)\nbalanced_accuracy_score = balanced_accuracy_score(y_concat_test, y_pred)\nprint(\"balanced acc:\", balanced_accuracy_score)\nprint(\"acc:\", accuracy)\nprint(\"precision:\", precision)\nprint(\"recall\", recall)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save model\nfrom joblib import dump\nmodel_save_path = '/kaggle/working/random_forest_model.joblib'\ndump(train_random_forest, model_save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the embeddings for the test examples\nsentences_final_test = X_final_test.tolist()\nembeddings_final_test = get_embeddings(sentences_final_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert embeddings for test examples to np array & save them \nembeddings_final_test = embeddings_final_test.numpy()\nnp.save(\"embeddings_final_test.npy\", embeddings_final_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make predictions for test examples\ny_pred_final = train_random_forest.predict(embeddings_final_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save predictions to csv\nids = list(range(len(y_pred_final)))  \n\ndf_final_predictions = pd.DataFrame({\n    'id': ids,\n    'class': y_pred_final\n})\n\ndf_final_predictions.to_csv('/kaggle/working/test_predictions.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train a logistic regression classifier\nclassifier = LogisticRegression()\nclassifier.fit(embeddings_train,y_train_numeric)\npredictions = classifier.predict(embeddings_concat_test)\naccuracy = accuracy_score(y_concat_test, y_pred)\nprecision = precision_score(y_concat_test, y_pred)\nrecall = recall_score(y_concat_test, y_pred)\nbalanced_accuracy_score = balanced_accuracy_score(y_concat_test, y_pred)\nprint(\"balanced acc:\", balanced_accuracy_score)\nprint(\"acc:\", accuracy)\nprint(\"precision:\", precision)\nprint(\"recall\", recall)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save model\nfrom joblib import dump\nmodel_save_path = '/kaggle/working/logistic_reg_model.joblib'\ndump(classifier, model_save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_final_logistic_reg = classifier.predict(embeddings_final_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final_predictions_logistic_reg = pd.DataFrame({\n    'id': ids,\n    'class': y_pred_final_logistic_reg\n})\n\ndf_final_predictions_logistic_reg.to_csv('/kaggle/working/test_predictions_logistic_reg.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_concat_test, predictions)\nprecision = precision_score(y_concat_test, predictions)\nrecall = recall_score(y_concat_test, predictions)\nbalanced_accuracy_score = balanced_accuracy_score(y_concat_test, predictions)\nprint(\"balanced acc:\", balanced_accuracy_score)\nprint(\"acc:\", accuracy)\nprint(\"precision:\", precision)\nprint(\"recall\", recall)from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nsvm_classifier = make_pipeline(StandardScaler(), SVC(kernel='linear', probability=True))\n\nsvm_classifier.fit(embeddings_train,y_train_numeric)\n\npredictions = svm_classifier.predict(embeddings_concat_test)\naccuracy = accuracy_score(y_concat_test, predictions)\nprecision = precision_score(y_concat_test, predictions)\nrecall = recall_score(y_concat_test, predictions)\nbalanced_accuracy_score = balanced_accuracy_score(y_concat_test, predictions)\nprint(\"balanced acc:\", balanced_accuracy_score)\nprint(\"acc:\", accuracy)\nprint(\"precision:\", precision)\nprint(\"recall\", recall)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save model\nfrom joblib import dump\nmodel_save_path = '/kaggle/working/svm_classifier_model.joblib'\ndump(svm_classifier, model_save_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_final_svm = svm_classifier.predict(embeddings_final_test)\ndf_final_predictions_svm = pd.DataFrame({\n    'id': ids,\n    'class': y_pred_final_svm\n})\n\ndf_final_predictions_svm.to_csv('/kaggle/working/test_predictions_svm.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_train = np.load(\"/kaggle/input/embeddings-1/embeddings.npy\")\nembeddings_val = np.load(\"/kaggle/input/embeddings-1/embeddings_val.npy\")\nembeddings_test = np.load(\"/kaggle/input/embeddings-1/embeddings_test.npy\")\nembeddings_final_test = np.load(\"/kaggle/input/embeddings-1/embeddings_final_test.npy\")\ny_train_numeric = np.load(\"/kaggle/input/embeddings-1/y_train_numeric.npy\")\ny_val_numeric = np.load(\"/kaggle/input/embeddings-1/y_val_numeric.npy\")\ny_test_numeric = np.load(\"/kaggle/input/embeddings-1/y_test_numeric.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:08:17.280876Z","iopub.execute_input":"2024-03-31T07:08:17.281903Z","iopub.status.idle":"2024-03-31T07:08:19.885282Z","shell.execute_reply.started":"2024-03-31T07:08:17.281848Z","shell.execute_reply":"2024-03-31T07:08:19.884466Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"y_concat_train = np.concatenate((y_train_numeric,y_val_numeric,y_test_numeric))\nembeddings_concat_train = np.concatenate((embeddings_train, embeddings_val,embeddings_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:08:20.875964Z","iopub.execute_input":"2024-03-31T07:08:20.876372Z","iopub.status.idle":"2024-03-31T07:08:20.962404Z","shell.execute_reply.started":"2024-03-31T07:08:20.876339Z","shell.execute_reply":"2024-03-31T07:08:20.961485Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ninput_shape = embeddings_train.shape[1]  \nmodel_nn = Sequential([\n    Dense(256, activation='relu', input_shape=(input_shape,)),\n    Dropout(0.25),  \n    Dense(128, activation='relu'),\n    Dropout(0.2),  \n    Dense(1, activation='sigmoid')\n])\nmodel_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model_nn.fit(embeddings_train, y_train_numeric, epochs=10, validation_data=(embeddings_val, y_val_numeric))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T03:29:29.159816Z","iopub.execute_input":"2024-03-31T03:29:29.160595Z","iopub.status.idle":"2024-03-31T03:30:10.674595Z","shell.execute_reply.started":"2024-03-31T03:29:29.160563Z","shell.execute_reply":"2024-03-31T03:30:10.673337Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m  92/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7807 - loss: 0.4537","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1711855775.217087      86 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.2388 - val_accuracy: 0.9332 - val_loss: 0.1667\nEpoch 2/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1652 - val_accuracy: 0.9386 - val_loss: 0.1546\nEpoch 3/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1532 - val_accuracy: 0.9440 - val_loss: 0.1478\nEpoch 4/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9484 - loss: 0.1462 - val_accuracy: 0.9506 - val_loss: 0.1276\nEpoch 5/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1365 - val_accuracy: 0.9545 - val_loss: 0.1249\nEpoch 6/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1348 - val_accuracy: 0.9533 - val_loss: 0.1245\nEpoch 7/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1286 - val_accuracy: 0.9592 - val_loss: 0.1104\nEpoch 8/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1263 - val_accuracy: 0.9564 - val_loss: 0.1161\nEpoch 9/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1218 - val_accuracy: 0.9576 - val_loss: 0.1129\nEpoch 10/10\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1199 - val_accuracy: 0.9574 - val_loss: 0.1158\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m model_nn\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m history \u001b[38;5;241m=\u001b[39m model_nn\u001b[38;5;241m.\u001b[39mfit(embeddings_train, y_train_numeric, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(embeddings_val, y_val_numeric))\n\u001b[0;32m---> 14\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:132\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    128\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n","\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 47991\n'y' sizes: 8469\n"],"ename":"ValueError","evalue":"Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 47991\n'y' sizes: 8469\n","output_type":"error"}]},{"cell_type":"code","source":"loss, accuracy = model_nn.evaluate(embeddings_test,y_test_numeric)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T03:32:51.027297Z","iopub.execute_input":"2024-03-31T03:32:51.027663Z","iopub.status.idle":"2024-03-31T03:32:51.814291Z","shell.execute_reply.started":"2024-03-31T03:32:51.027640Z","shell.execute_reply":"2024-03-31T03:32:51.813387Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1185\nTest Accuracy: 0.9574\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_probabilities = model_nn.predict(embeddings_final_test)\n# Convert probabilities to class labels \nthreshold = 0.5\npredicted_labels = (predicted_probabilities > threshold).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T03:34:18.349160Z","iopub.execute_input":"2024-03-31T03:34:18.349948Z","iopub.status.idle":"2024-03-31T03:34:21.178561Z","shell.execute_reply.started":"2024-03-31T03:34:18.349917Z","shell.execute_reply":"2024-03-31T03:34:21.177462Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_labels = predicted_labels.flatten()\n\nids = list(range(len(predicted_labels)))  \ndf_final_predictions_nn = pd.DataFrame({\n    'id': ids,\n    'class': predicted_labels\n})\n\ndf_final_predictions_nn.to_csv('/kaggle/working/test_predictions_nn.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T03:38:47.535433Z","iopub.execute_input":"2024-03-31T03:38:47.536163Z","iopub.status.idle":"2024-03-31T03:38:47.606413Z","shell.execute_reply.started":"2024-03-31T03:38:47.536134Z","shell.execute_reply":"2024-03-31T03:38:47.605635Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\ninput_shape = embeddings_train.shape[1]\nmodel_nn_2 = Sequential([\n    Dense(1024, activation='relu', input_shape=(input_shape,)),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(1024, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    \n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n    Dense(32, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.4),\n\n    \n    Dense(1, activation='sigmoid')\n])\nmodel_nn_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\ncheckpoint_path = '/kaggle/working/nn_model_13.keras'  \ncheckpoint = ModelCheckpoint(checkpoint_path, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\nhistory = model_nn_2.fit(embeddings_concat_train, y_concat_train, epochs=45, callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:08:44.404015Z","iopub.execute_input":"2024-03-31T07:08:44.404368Z","iopub.status.idle":"2024-03-31T07:11:08.488420Z","shell.execute_reply.started":"2024-03-31T07:08:44.404339Z","shell.execute_reply":"2024-03-31T07:11:08.487570Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m  35/2206\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4820 - loss: 1.2680   ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1711868950.659405      81 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5716 - loss: 0.8204\nEpoch 1: accuracy improved from -inf to 0.61006, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 12ms/step - accuracy: 0.5716 - loss: 0.8204\nEpoch 2/10\n\u001b[1m2202/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7058 - loss: 0.5749\nEpoch 2: accuracy improved from 0.61006 to 0.79036, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7060 - loss: 0.5746\nEpoch 3/10\n\u001b[1m2197/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2894\nEpoch 3: accuracy improved from 0.79036 to 0.89940, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2893\nEpoch 4/10\n\u001b[1m2205/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2509\nEpoch 4: accuracy improved from 0.89940 to 0.91056, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.2509\nEpoch 5/10\n\u001b[1m2205/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2406\nEpoch 5: accuracy improved from 0.91056 to 0.91736, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2406\nEpoch 6/10\n\u001b[1m2201/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.2268\nEpoch 6: accuracy improved from 0.91736 to 0.92177, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9205 - loss: 0.2268\nEpoch 7/10\n\u001b[1m2199/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2235\nEpoch 7: accuracy improved from 0.92177 to 0.92435, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2235\nEpoch 8/10\n\u001b[1m2201/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.2123\nEpoch 8: accuracy improved from 0.92435 to 0.92631, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.2123\nEpoch 9/10\n\u001b[1m2197/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.2083\nEpoch 9: accuracy improved from 0.92631 to 0.93053, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9298 - loss: 0.2083\nEpoch 10/10\n\u001b[1m2199/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.1977\nEpoch 10: accuracy improved from 0.93053 to 0.93233, saving model to /kaggle/working/nn_model_14.keras\n\u001b[1m2206/2206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9318 - loss: 0.1977\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\ndestination_path = '/kaggle/working/nn_model_14.keras'\nbest_model = load_model(destination_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:11:18.591974Z","iopub.execute_input":"2024-03-31T07:11:18.592684Z","iopub.status.idle":"2024-03-31T07:11:19.944914Z","shell.execute_reply.started":"2024-03-31T07:11:18.592649Z","shell.execute_reply":"2024-03-31T07:11:19.944099Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = best_model.evaluate(embeddings_test,y_test_numeric)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T06:29:59.334639Z","iopub.execute_input":"2024-03-31T06:29:59.335340Z","iopub.status.idle":"2024-03-31T06:30:01.483024Z","shell.execute_reply.started":"2024-03-31T06:29:59.335310Z","shell.execute_reply":"2024-03-31T06:30:01.482087Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.1121\nTest Accuracy: 0.9730\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_probabilities = best_model.predict(embeddings_final_test)\nthreshold = 0.5\npredicted_labels = (predicted_probabilities > threshold).astype(int)\npredicted_labels = predicted_labels.flatten()\n\nids = list(range(len(predicted_labels)))  \ndf_final_predictions_nn = pd.DataFrame({\n    'id': ids,\n    'class': predicted_labels\n})\n\ndf_final_predictions_nn.to_csv('/kaggle/working/test_predictions_nn_14.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T07:11:21.333623Z","iopub.execute_input":"2024-03-31T07:11:21.334211Z","iopub.status.idle":"2024-03-31T07:11:25.805496Z","shell.execute_reply.started":"2024-03-31T07:11:21.334176Z","shell.execute_reply":"2024-03-31T07:11:25.804679Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pred1 = pd.read_csv(\"/kaggle/input/predictions/prediction.csv\")\npred2 = pd.read_csv(\"/kaggle/input/predictions/test_predictions_logistic_reg.csv\")\npred3 = pd.read_csv(\"/kaggle/input/predictions/test_predictions_nn_7.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T06:34:00.210770Z","iopub.execute_input":"2024-03-31T06:34:00.211215Z","iopub.status.idle":"2024-03-31T06:34:00.239178Z","shell.execute_reply.started":"2024-03-31T06:34:00.211187Z","shell.execute_reply":"2024-03-31T06:34:00.238421Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"predictions1 = np.array(pred1['class'])\npredictions2 = np.array(pred2['class'])\npredictions3 = np.array(pred3['class'])","metadata":{"execution":{"iopub.status.busy":"2024-03-31T06:34:56.032588Z","iopub.execute_input":"2024-03-31T06:34:56.032957Z","iopub.status.idle":"2024-03-31T06:34:56.041384Z","shell.execute_reply.started":"2024-03-31T06:34:56.032929Z","shell.execute_reply":"2024-03-31T06:34:56.040443Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"combined_predictions = np.stack([predictions1, predictions2, predictions3], axis=1)\nmajority_vote = np.mean(combined_predictions, axis=1) > 0.5\nmajority_vote = majority_vote.astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T06:35:45.242379Z","iopub.execute_input":"2024-03-31T06:35:45.243050Z","iopub.status.idle":"2024-03-31T06:35:45.249611Z","shell.execute_reply.started":"2024-03-31T06:35:45.243020Z","shell.execute_reply":"2024-03-31T06:35:45.248633Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"ids = list(range(len(majority_vote)))  \ndf_final_predictions_majority = pd.DataFrame({\n    'id': ids,\n    'class': majority_vote\n})\ndf_final_predictions_majority.to_csv('/kaggle/working/majority.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T06:36:44.611667Z","iopub.execute_input":"2024-03-31T06:36:44.612049Z","iopub.status.idle":"2024-03-31T06:36:44.678699Z","shell.execute_reply.started":"2024-03-31T06:36:44.612020Z","shell.execute_reply":"2024-03-31T06:36:44.677920Z"},"trusted":true},"execution_count":7,"outputs":[]}]}