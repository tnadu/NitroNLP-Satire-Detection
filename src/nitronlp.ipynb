{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73414,"databundleVersionId":8090967,"sourceType":"competition"},{"sourceId":7980859,"sourceType":"datasetVersion","datasetId":4697254},{"sourceId":7985349,"sourceType":"datasetVersion","datasetId":4700477}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Setup**\n- import provided data as `main-dataset`\n- copy script which sets seed for multiple packages in the workind directory\n- set random seed, load datasets, and split the training dataset into a smaller training subset and a test subset","metadata":{}},{"cell_type":"code","source":"from shutil import copyfile\ncopyfile(src=\"../input/main-dataset/random_seed_setter.py\", dst=\"../working/random_seed_setter.py\")\n\nimport random_seed_setter\nrandom_seed_setter.set_random_seeds(42)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.084067Z","iopub.status.idle":"2024-03-30T23:15:58.084504Z","shell.execute_reply.started":"2024-03-30T23:15:58.084271Z","shell.execute_reply":"2024-03-30T23:15:58.084288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ntrain_dataset = pd.read_csv(\"/kaggle/input/main-dataset/train.csv\")\nprediction_dataset = pd.read_csv(\"/kaggle/input/main-dataset/test.csv\")\n\ntrain_data, test_data = train_test_split(train_dataset, train_size=0.8)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.087656Z","iopub.status.idle":"2024-03-30T23:15:58.088088Z","shell.execute_reply.started":"2024-03-30T23:15:58.087869Z","shell.execute_reply":"2024-03-30T23:15:58.087886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Stemming**\n(not actually used when fine-tuning the LLM, but given to the Random Forest)","metadata":{}},{"cell_type":"code","source":"from nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer(\"romanian\")\n\ndef stem(text):\n    return \" \".join([stemmer.stem(word) for word in str(text).split()])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.097913Z","iopub.status.idle":"2024-03-30T23:15:58.098243Z","shell.execute_reply.started":"2024-03-30T23:15:58.098083Z","shell.execute_reply":"2024-03-30T23:15:58.098097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[\"title\"] = train_dataset[\"title\"].apply(stem)\ntrain_dataset[\"content\"] = train_dataset[\"content\"].apply(stem)\ntrain_dataset.to_csv(\"train_stemmed.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.101784Z","iopub.status.idle":"2024-03-30T23:15:58.102224Z","shell.execute_reply.started":"2024-03-30T23:15:58.101999Z","shell.execute_reply":"2024-03-30T23:15:58.102018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_dataset[\"title\"] = prediction_dataset[\"title\"].apply(stem)\nprediction_dataset[\"content\"] = prediction_dataset[\"content\"].apply(stem)\nprediction_dataset.to_csv(\"test_stemmed.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.107650Z","iopub.status.idle":"2024-03-30T23:15:58.108454Z","shell.execute_reply.started":"2024-03-30T23:15:58.108214Z","shell.execute_reply":"2024-03-30T23:15:58.108235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Creating a Hugging Face dataset**","metadata":{}},{"cell_type":"code","source":"# it would be improbable that the title of an article would belong to a different class than its content, so the two columns are merged\ntrain_data[\"text\"] = train_data[\"title\"] + \" \" + train_data[\"content\"].fillna(\"\")\ntest_data[\"text\"] = test_data[\"title\"] + \" \" + test_data[\"content\"].fillna(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.119967Z","iopub.status.idle":"2024-03-30T23:15:58.120303Z","shell.execute_reply.started":"2024-03-30T23:15:58.120143Z","shell.execute_reply":"2024-03-30T23:15:58.120157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.drop([\"title\", \"content\", \"id\"], axis=1, inplace=True)\ntest_data.drop([\"title\", \"content\", \"id\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.123258Z","iopub.status.idle":"2024-03-30T23:15:58.123584Z","shell.execute_reply.started":"2024-03-30T23:15:58.123424Z","shell.execute_reply":"2024-03-30T23:15:58.123438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# most Hugging Face models expect the class field to be named `label`\ntrain_data.rename(columns = {\"class\": \"label\"}, inplace=True)\ntest_data.rename(columns = {\"class\": \"label\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.128266Z","iopub.status.idle":"2024-03-30T23:15:58.128596Z","shell.execute_reply.started":"2024-03-30T23:15:58.128431Z","shell.execute_reply":"2024-03-30T23:15:58.128444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[\"class\"] = train_data[\"class\"].astype(int)\ntest_data[\"class\"] = test_data[\"class\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.126726Z","iopub.status.idle":"2024-03-30T23:15:58.127084Z","shell.execute_reply.started":"2024-03-30T23:15:58.126923Z","shell.execute_reply":"2024-03-30T23:15:58.126937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some numerical data is mixed up in the dataset.\ntrain_data[\"text\"] = train_data[\"text\"].astype(str)\ntest_data[\"text\"] = test_data[\"text\"].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.131699Z","iopub.status.idle":"2024-03-30T23:15:58.132058Z","shell.execute_reply.started":"2024-03-30T23:15:58.131893Z","shell.execute_reply":"2024-03-30T23:15:58.131907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dict = train_data.to_dict(orient=\"list\")\ntest_dict = test_data.to_dict(orient=\"list\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.135239Z","iopub.status.idle":"2024-03-30T23:15:58.135570Z","shell.execute_reply.started":"2024-03-30T23:15:58.135404Z","shell.execute_reply":"2024-03-30T23:15:58.135418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\nds_train = Dataset.from_dict(train_dict)\nds_test = Dataset.from_dict(test_dict)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.142435Z","iopub.status.idle":"2024-03-30T23:15:58.142888Z","shell.execute_reply.started":"2024-03-30T23:15:58.142641Z","shell.execute_reply":"2024-03-30T23:15:58.142658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Fine-tuning a LLM**\nThe model used, `readerbench/RoBERT-small`, is trained on data written in Romanian, and is small enough to be fine-tuned with our limited computing resources.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"readerbench/RoBERT-small\")\n\ndef preprocess(data):\n    return tokenizer(data[\"text\"], truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.143973Z","iopub.status.idle":"2024-03-30T23:15:58.144270Z","shell.execute_reply.started":"2024-03-30T23:15:58.144121Z","shell.execute_reply":"2024-03-30T23:15:58.144133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_ds_train = ds_train.map(preprocess, batched=True)\ntokenized_ds_test = ds_test.map(preprocess, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.150704Z","iopub.status.idle":"2024-03-30T23:15:58.151065Z","shell.execute_reply.started":"2024-03-30T23:15:58.150894Z","shell.execute_reply":"2024-03-30T23:15:58.150908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.152192Z","iopub.status.idle":"2024-03-30T23:15:58.152493Z","shell.execute_reply.started":"2024-03-30T23:15:58.152338Z","shell.execute_reply":"2024-03-30T23:15:58.152350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# not installed in Kaggle environment\n!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.153609Z","iopub.status.idle":"2024-03-30T23:15:58.153932Z","shell.execute_reply.started":"2024-03-30T23:15:58.153752Z","shell.execute_reply":"2024-03-30T23:15:58.153779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(generated_predictions):\n    predictions, labels = generated_predictions\n    # predictions returned as a bidimensional matrix, with columns for classes, and rows for individual articles;\n    # value at (i, j) in matrix indicates score for class j of entry i\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.154873Z","iopub.status.idle":"2024-03-30T23:15:58.155178Z","shell.execute_reply.started":"2024-03-30T23:15:58.155029Z","shell.execute_reply":"2024-03-30T23:15:58.155042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = {0: \"NON-SATIRE\", 1: \"SATIRE\"}\nlabel2id = {\"NON-SATIRE\": 0, \"SATIRE\": 1}","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.159252Z","iopub.status.idle":"2024-03-30T23:15:58.159574Z","shell.execute_reply.started":"2024-03-30T23:15:58.159411Z","shell.execute_reply":"2024-03-30T23:15:58.159424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"readerbench/RoBERT-small\", num_labels=2, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.160756Z","iopub.status.idle":"2024-03-30T23:15:58.161104Z","shell.execute_reply.started":"2024-03-30T23:15:58.160948Z","shell.execute_reply":"2024-03-30T23:15:58.160961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\n# avoid wandb prompt for API token\nwandb.init(mode='disabled')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.162184Z","iopub.status.idle":"2024-03-30T23:15:58.162621Z","shell.execute_reply.started":"2024-03-30T23:15:58.162385Z","shell.execute_reply":"2024-03-30T23:15:58.162403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"robert-small-satire-classification-intermediary-weights\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds_train,\n    eval_dataset=tokenized_ds_test,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\ntrainer.save_model(\"robert-small-satire-classification\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.164420Z","iopub.status.idle":"2024-03-30T23:15:58.164879Z","shell.execute_reply.started":"2024-03-30T23:15:58.164636Z","shell.execute_reply":"2024-03-30T23:15:58.164653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shutil import make_archive\nmake_archive(\"/kaggle/working/robert-small-satire-classification-intermediary-weights\", \"zip\", \"/kaggle/working/robert-small-satire-classification-intermediary-weights\")\nmake_archive(\"/kaggle/working/robert-small-satire-classification\", \"zip\", \"/kaggle/working/robert-small-satire-classification\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.166009Z","iopub.status.idle":"2024-03-30T23:15:58.166435Z","shell.execute_reply.started":"2024-03-30T23:15:58.166214Z","shell.execute_reply":"2024-03-30T23:15:58.166231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Predictions**","metadata":{}},{"cell_type":"code","source":"# the archive containing the final version of the fine-tuned model should be manually imported as a dataset of the Kaggle notebook\ntokenizer_fine_tuned = AutoTokenizer.from_pretrained(\"/kaggle/input/robert-small-satire-classification\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.173386Z","iopub.status.idle":"2024-03-30T23:15:58.173848Z","shell.execute_reply.started":"2024-03-30T23:15:58.173606Z","shell.execute_reply":"2024-03-30T23:15:58.173624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# make sure both the test dataset and the weights of the model are loaded into the same device\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\nmodel_fine_tuned = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/robert-small-satire-classification\", num_labels=2, id2label=id2label, label2id=label2id).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.175120Z","iopub.status.idle":"2024-03-30T23:15:58.175547Z","shell.execute_reply.started":"2024-03-30T23:15:58.175322Z","shell.execute_reply":"2024-03-30T23:15:58.175340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_dataset[\"text\"] = prediction_dataset[\"title\"] + \" \" + prediction_dataset[\"content\"].fillna(\"\")\nprediction_dataset.drop([\"title\", \"content\", \"id\"], axis=1, inplace=True)\nprediction_data = prediction_dataset[\"text\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.177083Z","iopub.status.idle":"2024-03-30T23:15:58.177411Z","shell.execute_reply.started":"2024-03-30T23:15:58.177250Z","shell.execute_reply":"2024-03-30T23:15:58.177264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\n# the prediction dataset will be fed to the model in batches of 16\nfor i in range(len(prediction_data) // 16):\n    # clear any cached data from the previous batch\n    torch.cuda.empty_cache()\n\n    # process the next batch, while returning the tensors in pytorch format, and then sending them to the available device\n    tokenized_prediction_data = tokenizer_fine_tuned(prediction_data[i * 16:(i + 1) * 16], return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    with torch.no_grad():\n        logits = model_fine_tuned(**tokenized_prediction_data).logits\n        predictions.append(logits)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:15:58.184587Z","iopub.status.idle":"2024-03-30T23:15:58.184971Z","shell.execute_reply.started":"2024-03-30T23:15:58.184788Z","shell.execute_reply":"2024-03-30T23:15:58.184808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# last batch, which might be incomplete, will be processed below\ntorch.cuda.empty_cache()\n\ntokenized_prediction_data = tokenizer_fine_tuned(prediction_data[len(prediction_data) // 16 * 16:], return_tensors=\"pt\", truncation=True, padding=True).to(device)\nwith torch.no_grad():\n    logits = model_fine_tuned(**tokenized_prediction_data).logits\n    predictions.append(logits)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:16:16.962886Z","iopub.execute_input":"2024-03-30T23:16:16.963785Z","iopub.status.idle":"2024-03-30T23:16:17.015093Z","shell.execute_reply.started":"2024-03-30T23:16:16.963743Z","shell.execute_reply":"2024-03-30T23:16:17.014023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = []\nfor logit_set in predictions:\n    # the same format, as explained previously\n    predicted_labels.extend(logit_set.argmax(axis=1).tolist())\n    \nprediction_dataframe = pd.DataFrame(predicted_labels, columns=[\"class\"])\nprediction_dataframe.to_csv(\"prediction.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:21:10.760322Z","iopub.execute_input":"2024-03-30T23:21:10.760932Z","iopub.status.idle":"2024-03-30T23:21:10.848957Z","shell.execute_reply.started":"2024-03-30T23:21:10.760900Z","shell.execute_reply":"2024-03-30T23:21:10.848202Z"},"trusted":true},"execution_count":null,"outputs":[]}]}